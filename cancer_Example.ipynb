{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5hoU17rucF6y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bCz9Zp9rvRb5"
   },
   "outputs": [],
   "source": [
    "# url for the dataset\n",
    "url = 'https://github.com/burskapasi/DeepLearningData/blob/main/cancer.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/burhan/Downloads/Burhanuddin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jjCZOsW9eISD"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('/Users/burhan/Downloads/Burhanuddin/cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "qvkh2h13fIuW",
    "outputId": "befc550c-1b9f-4e3d-e3fb-c30de6e67615"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "5  ...          23.75           103.40       741.6            0.1791   \n",
       "6  ...          27.66           153.20      1606.0            0.1442   \n",
       "7  ...          28.14           110.60       897.0            0.1654   \n",
       "8  ...          30.73           106.20       739.3            0.1703   \n",
       "9  ...          40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "7                  0.11510          NaN  \n",
       "8                  0.10720          NaN  \n",
       "9                  0.20750          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QoyMlQUHmPm-"
   },
   "outputs": [],
   "source": [
    "# As last column has a lot of NaN. Droping the column\n",
    "df.drop('Unnamed: 32', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fiQps4qnoso",
    "outputId": "0660e880-1c6f-4142-b5a4-3ffa15ce1397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burhan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "#  Creating a column to convert diagnosis to binary. First filling it with 0. Changing each row with M to 1 in the cancer column. \n",
    "df['cancer'] = 0 # Benign\n",
    "df['cancer'].loc[df['diagnosis'] == 'M'] = 1 # Malign\n",
    "# Droping the diagnosis column\n",
    "df.drop('diagnosis', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiN46a9QoG86",
    "outputId": "ed56d161-5739-42c3-8b8b-e5a77d2346de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: cancer, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the column cancer made the changes\n",
    "df['cancer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Db88L_BeqNB3"
   },
   "outputs": [],
   "source": [
    "# Creating input and output variables for the model\n",
    "X = df.drop(columns=['cancer'])\n",
    "y = df[['cancer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Ib0eVhutrQXa",
    "outputId": "6d1ba073-d5d4-4128-cfa3-3a65f48e6851"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302        17.99         10.38          122.80     1001.0   \n",
       "1    842517        20.57         17.77          132.90     1326.0   \n",
       "2  84300903        19.69         21.25          130.00     1203.0   \n",
       "3  84348301        11.42         20.38           77.58      386.1   \n",
       "4  84358402        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Checking if cancer column was dropped\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "Jn8wElJWrVf6",
    "outputId": "af228031-c6f8-47ca-b601-576abd9c33a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cancer\n",
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "5        1\n",
       "6        1\n",
       "7        1\n",
       "8        1\n",
       "9        1\n",
       "10       1\n",
       "11       1\n",
       "12       1\n",
       "13       1\n",
       "14       1\n",
       "15       1\n",
       "16       1\n",
       "17       1\n",
       "18       1\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if it contains only cancer column\n",
    "y.head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QaDrgG29rbZV"
   },
   "outputs": [],
   "source": [
    "# Creating model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = X.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TiKCvy03r4wR"
   },
   "outputs": [],
   "source": [
    "# Spliting the data to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QvQ3Z4rTr5x1"
   },
   "outputs": [],
   "source": [
    "# scaling the values\n",
    "x_scaler = MinMaxScaler()\n",
    "X_train = x_scaler.fit_transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHlWY2OTr_Ki",
    "outputId": "7bc1b75e-2f33-48ea-fd05-57f786a2a1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min x: 0.0\n",
      "Max x: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# # make sure values are between 0-1\n",
    "print(\"Min x:\", np.min(X_train))\n",
    "print(\"Max x:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WfUXXAJsClN",
    "outputId": "45676b9f-93eb-4e1e-94b0-5ee2158f7a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.6194\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.6194\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.6194\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6194\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.6194\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6194\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.6194\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.6194\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6194\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6513 - accuracy: 0.6352\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.6614\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.7087\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.7612\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.8268\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.8609\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.8766\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.8793\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8976\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8924\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8950\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.9029\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.9055\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.9055\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.9055\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.9055\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.9055\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.9081\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.9108\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.9108\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.9108\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.9108\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.9134\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.9186\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.9186\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9108\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9160\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9160\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9239\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9239\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9160\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9265\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.9318\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2028 - accuracy: 0.9318\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9318\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9318\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9291\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9318\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1840 - accuracy: 0.9344\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9344\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9318\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9370\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9318\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9370\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9344\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9396\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9396\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9449\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9423\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9475\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9501\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9501\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9528\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9580\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9580\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9580\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9580\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9580\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9606\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9580\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9580\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9606\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9580\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9606\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9633\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9633\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9606\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9606\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9633\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9633\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9633\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9659\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9633\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9659\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.9659\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9685\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9711\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9685\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9685\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9738\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9790\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9816\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9790\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9790\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29vPIxSysls8",
    "outputId": "ebf2d2d6-5c36-463a-873a-3447f1d3f7e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "UVgdmHUTsmeS",
    "outputId": "0e721b0e-36f1-469d-8bd5-3183cb6e12a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting training loss\n",
    "loss_values = history_dict['loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label = \"Training Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cancer Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
